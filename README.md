# ğŸ¤Ÿ SIGN LANGUAGE INTERPRETER

Live deployment: ğŸ‘‰ [asl-interpreter.streamlit.app](https://asl-interpreter.streamlit.app/)

A real-time American Sign Language (ASL) interpreter built using **MediaPipe**, **TensorFlow**, and **Streamlit**. This is a full-stack **Software Engineering + Machine Learning** project that captures hand gestures from a webcam, classifies them using a trained deep learning model, and translates them into English characters or words.

---

## ğŸš€ Features

- ğŸ–ï¸ Real-time hand gesture detection via webcam
- ğŸ§  Pre-trained deep learning model (`.h5`) for classification
- ğŸ¯ Integrated with **MediaPipe** for accurate hand landmark tracking
- ğŸ’» Web app interface using **Streamlit**
- ğŸ¥ Webcam-based data collection script
- âš™ï¸ Scripts to train and test custom models
- ğŸ“¦ Deployed on [Streamlit Cloud](https://asl-interpreter.streamlit.app/)

---

## ğŸ§° Tech Stack

| Layer             | Technology                          |
|------------------|--------------------------------------|
| Frontend          | Streamlit (Python-based UI framework) |
| Backend / Logic   | Python, OpenCV, MediaPipe, TensorFlow |
| ML Model          | Keras `.h5` model trained on custom ASL data |
| Deployment        | Streamlit Cloud                     |
| Dataset (optional)| Collected via webcam (`collect_img.py`) |

---

## ğŸ“‚ File Structure

```
â”œâ”€â”€ app.py                # Main Streamlit app
â”œâ”€â”€ collect_img.py        # Script to collect gesture images
â”œâ”€â”€ train_deep.py         # Model training script
â”œâ”€â”€ test_deep.py          # Script to test model accuracy
â”œâ”€â”€ deep_model.h5         # Trained Keras model
â”œâ”€â”€ data.pickle           # Pickled data (optional)
â”œâ”€â”€ label_encoder.pkl     # Label encoder for model predictions
â”œâ”€â”€ deep_model_info.pkl   # Additional model metadata
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ runtime.txt           # Python runtime version
â”œâ”€â”€ packages.txt          # OS-level dependencies (optional)
```

---

## ğŸ’» How to Run Locally

### ğŸ§± Prerequisites
- Python 3.10+
- pip

### ğŸ”§ Installation

```bash
git clone https://github.com/itsarbab0/SIGN-LANGUAGE-INTERPRETER.git
cd SIGN-LANGUAGE-INTERPRETER

# (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

---

### â–¶ï¸ Run the App

```bash
streamlit run app.py
```

Once launched, allow webcam access and start signing!

---

## ğŸ§ª Train Your Own Model

If you'd like to train your own gesture classifier:

```bash
python collect_img.py    # Collect custom images using webcam
python train_deep.py     # Train the model
python test_deep.py      # Test the trained model
```

Your model will be saved as `deep_model.h5`.

---

## ğŸŒ Deployment

This app is deployed at:

ğŸ‘‰ **[https://asl-interpreter.streamlit.app/](https://asl-interpreter.streamlit.app/)**

It is hosted on [Streamlit Cloud](https://streamlit.io/cloud).

---

## ğŸ‘¤ Author

**Arbab Kareem**  
GitHub: [@itsarbab0](https://github.com/itsarbab0)

---

## ğŸ“œ License

This project is for educational purposes. You are free to fork and extend it with proper credit.

---

## ğŸ™Œ Acknowledgements

- [Streamlit](https://streamlit.io/)
- [MediaPipe](https://google.github.io/mediapipe/)
- [TensorFlow](https://www.tensorflow.org/)
